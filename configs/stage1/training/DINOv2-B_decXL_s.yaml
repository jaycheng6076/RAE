stage_1:
  target: stage1.rae_s.RAE
  params:
    encoder_cls: 'Dinov2withNorm'
    encoder_config_path: 'facebook/dinov2-with-registers-base'
    encoder_input_size: 224
    encoder_params:
      dinov2_path: 'facebook/dinov2-with-registers-base'
      normalize: true
    decoder_config_path: 'configs/decoder/ViTXL'
    noise_tau: 0.8 # training 0.8, at inference time always set to 0
    reshape_to_2d: true
    #normalization_stat_path: 'models/stats/dinov2/wReg_base/imagenet1k/stat.pt'
    quantizer:
      target: stage1.bottleneck.socae.SparseOrthogonalContrastiveAutoEncoder
      params:
        input_dim: 768  # DINOv2-Base hidden size
        hidden_dim: 12288  # 16x expansion for sparse latent (768 * 16)
        topk: 32  # number of top activations to keep
        larger_topk: 128  # required param, must match pre-trained model
        encoder_bias: false  # must match pre-trained model architecture
      ckpt: results/socae/checkpoints/ep-last.pt  # pre-trained SOCAE checkpoint
  #ckpt: results/stage1/rae/checkpoints/ep-last.pt

eval:
  eval_interval: 2500 # Eval interval by optimization step
  eval_model: true # By default only evaluates EMA model. Set to true to eval non-EMA model as well.
  data_path: '/home/jianpengcheng_meta_com/imagenet/val/' # path to ImageNet val images
  reference_npz_path: '/home/jianpengcheng_meta_com/imagenet/VIRTUAL_imagenet256_labeled.npz' # packed npz of ImageNet val images for FID calculation
  metrics: ['psnr', 'ssim', 'rfid'] # metrics to calculate

training:
  epochs: 16
  ema_decay: 0.9978
  global_batch_size: 512
  num_workers: 8
  clip_grad: 0.0
  log_interval: 100
  checkpoint_interval: 1 # every 1 epoch
  sample_every: 2500
  optimizer:
    lr: 2.0e-4
    betas: [0.9, 0.95]
    weight_decay: 0.0
  scheduler:
    type: cosine
    warmup_epochs: 1
    decay_end_epoch: 16
    base_lr: 2.0e-4
    final_lr: 2.0e-5
    warmup_from_zero: true

# eval:
#   eval_interval: 2500
#   eval_model: true
#   data_path: 'data/imagenet/val/'
#   reference_npz_path: 'data/imagenet/val_256.npz'
#   metrics: ['psnr', 'ssim', 'rfid']

gan:
  disc:
    arch:
      dino_ckpt_path: 'models/discs/dino_vit_small_patch8_224.pth'
      ks: 9
      norm_type: 'bn'
      using_spec_norm: true
      recipe: 'S_8'
    optimizer:
      lr: 2.0e-4
      betas: [0.9, 0.95]
      weight_decay: 0.0
    scheduler:
      type: cosine
      warmup_epochs: 1
      decay_end_epoch: 16
      base_lr: 2.0e-4
      final_lr: 2.0e-5
      warmup_from_zero: true
    augment:
      prob: 1.0
      cutout: 0.0
  loss:
    disc_loss: hinge
    gen_loss: vanilla
    disc_weight: 0.75
    perceptual_weight: 1.0
    disc_start: 8
    disc_upd_start: 6
    lpips_start: 0
    max_d_weight: 10000.0
    disc_updates: 1
